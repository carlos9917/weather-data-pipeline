---
title: "Weather Data Pipeline"
author: "Carlos Peralta"
format: revealjs
---

## Introduction

This project is a classic example of an ETL (Extract, Transform, Load) pipeline:

   * Extract: The data_ingestion scripts connect to external data sources (weather data from meteorological data centers) and download the raw weather forecast data (GRIB or NetCDF files).
   * Transform: The data_processing scripts take the raw data, clean it, select the necessary parameters, calculate new variables (like wind gusts), and convert it into an optimized format (Zarr or duckdb).
   * Load: The final, processed data is loaded into a storage system (data/processed_data/) where it can be efficiently accessed by the visualization scripts to generate maps and power the
     interactive dashboard.


## Data Sources

- **Global Model: GFS (Global Forecast System)**
    - Chosen for its global coverage, free availability, and frequent updates (every 6 hours).
    - Provides a large-scale context for weather patterns.
- **Regional Model: MET (Norwegian Meteorological Institute)**
    - Covers Northern Europe, including Scandinavia and Latvia, providing high-resolution local detail.
    - Offers more accurate forecasts for the region of interest.

## Pipeline Architecture

The pipeline is designed as a modular, automated system:

1.  **Orchestration**:
    - A shell script (`scr/run_pipeline.sh`) serves as the main entry point.
    - It can run in `scheduler`, `dashboard`, `manual`, or `default` modes.
    - The scheduler mode runs the pipeline every 6 hours, fetching the latest data.
    - `orchestration/pipeline_scheduler.py` is the core script that coordinates the pipeline's execution.

2.  **Data Ingestion**:
    - `data_ingestion/gfs_downloader.py` and `data_ingestion/met_downloader.py` handle the download of GFS and MET data, respectively.

3.  **Data Processing**:
    - `data_processing/process_data.py` and `data_processing/process_met_data.py` process the raw data into a usable format (zarr or duckdb).
    - `data_processing/calculate_wind_gust.py` implements a simplified wind gust calculation.

4.  **Visualization**:
    - `visualization/create_visualizations.py` and `visualization/create_met_visualizations.py` generate static visualizations.
    - `visualization/run_dashboard.py` launches an interactive dashboard built with Python Dash.

## Visual Outputs

- **Static Maps**:
    - Time-stepped maps are generated for key parameters (precipitation, cloud cover, wind).
    - These provide a clear, at-a-glance view of the weather forecast.
- **Interactive Dashboard**:
    - A Python Dash application (`interactive_dashboard.py`) allows for interactive exploration of the data.
    - Users can likely select different parameters, time steps, and regions to visualize.

## Example static maps: Temperature

![Temperature map snapshot](figs/temperature_20250906_0600.png)

## Example static maps: Wind 
![Wind map snapshot](figs/wind_speed_10m_20250903_0600.png)



## Reasoning and Trade-offs

- **Choice of GFS**:
    - **Reasoning**: Global coverage, no cost, and frequent updates make it ideal for a prototype.
    - **Trade-off**: Lower resolution compared to other models like ECMWF.
- **Choice of MET**:
    - **Reasoning**: Provides high-resolution data for the specific region of interest (Northern Europe).
    - **Trade-off**: Limited geographical coverage.
- **Pipeline Automation**:
    - **Reasoning**: The scheduler ensures that the data is always up-to-date without manual intervention.
    - **Trade-off**: Requires a persistent process to be running.
- **Interactive Dashboard**:
    - **Reasoning**: Provides a much richer user experience and allows for deeper exploration of the data.
    - **Trade-off**: More complex to develop and maintain than static visualizations.

## Possible extensions

- **Include IFS**: The ECMFWF model is widely regarded as the most reliable for the medium range scale.

- **Include a validation pipeline**: Currently the scripts only download data and plot them, but 
  in order to validate the simulations one would need to also include a proper model verification.

- **Include ensemble data**: all current operational models provide an ensemble. In this case we are only
   downloading the deterministic version of GFS, and a post-processed version of the MET Norway model.

- **Download observational data**: needed to do the validation of the simulations.
